\documentclass[review]{elsarticle}

\usepackage{lineno,hyperref}

\usepackage{amsmath}

\modulolinenumbers[1]

\usepackage{soul}
\usepackage{marginnote}


\journal{Journal of \LaTeX\ Templates}


%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}


%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
%\bibliographystyle{elsarticle-num}

%% APA style
% \bibliographystyle{model5-names}\biboptions{authoryear}

%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{subcaption}

\begin{document}

\begin{frontmatter}

\title{Forecasting the black Sigatoka development rate: A comparison of machine learning techniques 
%\tnoteref{mytitlenote}
}
%\tnotetext[mytitlenote]{Fully documented templates are %available in the elsarticle package on \href{http://%www.ctan.org/tex-archive/macros/latex/contrib/elsarticle}%{CTAN}.}

%% Group authors per affiliation:
\author[afiLuisAlex]{Luis-Alexander Calvo-Valverde\fnref{myfootnote}}
\ead{lualcava.sa@gmail.com}
\fntext[myfootnote]{Corresponding author. (506)70104420}

\author[afiCorbana] {Mauricio Guzm\'an-Quesada}
\author[afiCorbana]{Jos\'e-Antonio Guzm\'an-Alvarez}
\author[afiPablo]{Pablo Alvarado-Moya}

\address[afiLuisAlex]{DOCINADE, Instituto Tecnol\'ogico de Costa Rica, 
Computer Research Center, Multidisciplinar program eScience, 
CNCA/CeNAT, Cartago, Costa Rica}

\address[afiCorbana]{Direcci\'on de Investigaciones, Corporaci\'on Bananera Nacional S.A., Gu\'apiles, Costa Rica}

\address[afiPablo]{DOCINADE, Instituto Tecnol\'ogico de Costa Rica, Cartago, Costa Rica}




\begin{abstract}
Pending.
\end{abstract}

\begin{keyword}
\texttt{Machine learning \sep Black Sigatoka \sep Support vector regression \sep
Banana disease prediction \sep Biological warning system }
\end{keyword}

\end{frontmatter}

\linenumbers

\section{Introduction}

\marginnote{La bibliografia debe ser autor, anno}

The black Sigatoka disease caused by the fungus {\it Mycosphaerella
  fijiensis Morelet} is the major pathological problem of banana and
plantain crops in Central America, Panama, Colombia and Ecuador, as in
many parts of Africa and Asia \citep{MarinVargas1995}.

This disease attacks the plant leaves producing a rapid deterioration
of the leaf area, affects the growth and productivity of the plants due to the impairment of their photosinthetic ability  causes a reduction in the quality
of the fruit, and promotes premature maturation of bunches, which is
the major cause of product losses associated with the black Sigatoka. \figurename
$.$\ref{figura1} shows three stages of this disease.

Phytopathological studies point out that precipitation, temperature,
relative humidity and wind are the main climatic variables that affect
its development \citep{MarinVargas1995}.
 	 
\begin{figure}[h] 
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{Roya_a}
  \caption{}
  \label{fig:sfig1}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{Roya_b}
  \caption{}
  \label{fig:sfig2}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{Roya_c}
  \caption{}
  \label{fig:sfig3}
\end{subfigure}
\caption{Examples of three disease stages of the black Sigatoka. (a) Initial stage. (b) Intermediate stage, and (c) Advanced stage.} 
\label{figura1} 
\end{figure}

In Costa Rica for the control of black Sigatoka is necessary the application of chemical fungicides. Depending of the zone of production and the weather conditions 45 – 55 cycles/year of fungicides is needed to keep this disease under control and to produce fruit with quality for exportation. This represent a cost per hectare per year ranged between \$1600 USD and \$2000 USD, about 0,64 - 0.80 cents of the cost of production of a box of 18.14 kilograms. Overall, this represents 10\% to 12\% of the total production cost.

The past and present rates of disease development  can in principle be used
to predict its future behavior and to determine whether
particular fungicide spray schedules will be able to effectively and
economically control the disease \citet{ChuangJeger1987}.

There are efforts to apply machine learning methods for
decision-making in agriculture, including the control of crop
diseases. For example, \cite{Camargo2012} present an intelligent
system for the assessment of crop disorders, \cite{Huang2010}
introduce a plant virus identification method based on neural networks with an evolutionary preprocessing stage, \cite{Kim2014} summarize in
their survey crop pests prediction methods using regression and
machine learning approaches, while \cite{Zhao2013} present an
intelligent agricultural forecasting system based on wireless sensor
networks.

In this work, we compare four machine learning techniques (support vector
regression (SVR), echo state networks (ESN), ridge regression and
ordinary least squares linear regression) to predict the development rate of the black Sigatoka disease.

The main contribution of this work is a comparison between machine
learning methods to forecast black Sigatoka development rate. 
\marginnote{FALTA COMPLETAR esta parte}


\section{Materials and methods}

\subsection{Concepts}
\subsubsection{Black Sigatoka disease}

Black Sigatoka, disease caused by the fungus Mycosphaerella fijiensis Morelet, is the main problem phytopathologic of banana and plantain crops in Central America \citep{MarinVargas1995}. 

This disease attacks the leaves of plants producing a rapid deterioration of the leaf area. It affects the growth and productivity of plants by decreasing photosynthetic capacity. Also causes a reduction in quality of the fruit \citep{MarinVargas1995}. 

The climate has a major effect on the behavior of the black Sigatoka. Precipitation, temperature, relative humidity and wind are the main climatic variables affecting the development of this disease \citep{MarinVargas1995}.

\subsubsection{Biological warning system}

The early warning system for black Sigatoka is an adaptation of the yellow Sigatoka warning system developed by Ganry and Meyer and modified by Ganry and Laville to use for controlling yellow Sigatoka in Cameroon. Ternesien and Fouré  later improved Ganry and Laville's system. The latter system is based on weekly observations of disease symtoms on young leaves of the plant, according to Fouré's symptom (stages) descriptions. Arbitrary coefficientes, based on incidence and severity of disease development, are used to calculate two variables: gross sum and state of evolution. Gross sum is based on the stage present and an arbitrary coefficient, which increases with the advance of the symptoms and the juvenility of the leaf. The state of evolution is calculated using the gross sum and the foliar emission period. Although threshold levels were initially suggested as a guide to spray timing, the fluctuation of these two variables was found to better define appropiate times to spray \citep{Marinetal2003}.

\subsubsection{Support Vector Regression (SVR)}
From the perspective of Support Vector Regression (SVR) the regression function $y = f(s)$ for a given dataset $D=\{(s_i,y_i)\}_{i=1}^n$ , is represented as a linear function of the form \citep{Wei2013}:
$$f(s)=w^Ts+b$$
where $w$ and $b$ are respectively the weight vector and the intercept of the model, and they are selected to find an optimal fit to the data available in $D$.

For nonlinear cases, one proceeds by mapping the input p-dimensional vectors via a nonlinear function $\phi : R^p\rightarrow F$, onto the feature space $F$.  After nonlinear mapping, the regression function evolves to a pervasive form:

$$f(s)=w^T \phi (s)+b$$

SVR uses the $ \epsilon -insensitive \ loss \ function$:

\[l= {\Bigr| y - f(s) \Bigr| }_{\epsilon } = 
\left\{\begin{array}{lcl}
	0 & \mbox{} & {\Bigr| y - f(s) \Bigr| } \leq \epsilon \\
	 &  & \\
	{\Bigr| y - f(s) \Bigr| - \epsilon} & \mbox{} & else\\ \end{array} \right. \] 

which ignores the error if the difference between the prediction value and the actual value is smaller than $ \epsilon$.
The $ \epsilon -insensitive \ loss \ function$ allows to find the coefficients $w$ and $b$ by solving a convex optimization problem, which balances the empirical error and the generalization ability. In SVR, the empirical error is measured by the loss function є-insensitive and the generalization ability is measured by the Euclidean norm of $w$ \citep{XXXX201X}. Then, the optimization problem to identify the regression model can be formulated by \citep{Wei2013}:
\marginnote{Falta completar la cita XXXXX con el libro de SVR}

\begin{equation} 
\begin{aligned}
& \underset{}{\text{miimize}}
& & J(w,\xi_i , \xi_i^* ) = \frac{1}{2}   \Bigr| \Bigr| w \Bigr| \Bigr|^2 + C \sum_{i=1}^{n} (\xi_i , \xi_i^* )    \\
& \text{subject to}
& & \begin{array}{lcl} 
y_i - w^T \phi (s) - b  \leq \epsilon + \xi_i   \\
w^T \phi (s) + b - y_i \leq \epsilon + \xi_i^* & i= 1,2,...,n \\
\xi_i , \xi_i^* \geq 0  \\
\end{array}
\end{aligned}
\end{equation}  
where $C$ denotes the penalty parameter between empirical and generalization errors, and  $\xi_i , \xi_i^*$ are slack variables. \figurename
$.$\ref{figura2} shows this situation.

\begin{figure}[h] 
 \centering
 \includegraphics[scale=.9]{SVR}
 \caption{$\epsilon -insensitive \ loss \ function \citep{Wei2013}.$} 
 \label{figura2} 
\end{figure}
 
The solution of this optimization problem by the Lagrange method is given by:\\
$$ f(s) = w^T \phi (s) + b = \sum_{i=1}^{n} (\alpha_i - \alpha_i^*) K (s,s_i) + b $$ 
where $\alpha_i - \alpha_i^*$  are the Lagrange multipliers of the optimization problem’s dual form and $K(s_i,s_j )$ is the kernel function satisfying the Mercer condition, and holds:
$$K(s_i,s_j ) = \big \langle  \phi(s_i) , \phi(s_j)  \big \rangle $$
Operations in the kernel function $K(s,s_i )$ are performed in the input space rather than in the potentially high dimensional feature space of $\phi$ \citep{Alonso2013}.

\subsubsection{Ordinary least squares regression}
This method fits a linear model with coefficients $w = (w1,..,wp)$ to minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation. Mathematically it solves a problem of the form \citep{ scikit-learn2011}:

$$\min_{w} \Bigr| \Bigr| Xw - y \Bigr| \Bigr|_2^2  $$
where $X$ denotes the features matriz. \\
According Pedregosa et al. \citep{ scikitlearn2011}  the coefficient estimates for Ordinary Least Squares rely on the independence of the model terms. When terms are correlated and the columns of the design matrix $X$ have an approximate linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed response, producing a large variance. This situation of multicollinearity can arise, for example, when data are collected without an experimental design

\subsubsection{Ridge regression}
The ridge regression addresses some of the problems of ordinary least squares regression by imposing a penalty on the size of the coefficients. The ridge coefficients minimize a penalized residual sum of squares  \citep{scikitlearn2011}:
$$\min_{w} { \Bigr| \Bigr| Xw - y \Bigr| \Bigr|_2^2  + \alpha \Bigr| \Bigr| w \Bigr| \Bigr|_2^2 } $$
Here, $\alpha \ \textgreater \  0$ is a complexity parameter that controls the amount of shrinkage: the larger the value of $\alpha$, the greater the amount of shrinkage and thus the coefficients become more robust to collinearity.

\subsubsection{Echo State Networks (ESN)}
Recurrent Neural Networks (RNN) are useful for temporal patterns, but when they are trained with backpropagation methods, they are very slow.  Echo State Network (ESN) is an alternative training method to solve that problem.  ESN is based on the observation that if a random RNN possesses certain algebraic properties, training only a linear readout from it is often sufficient to achieve excellent performance in practical applications \citep{Lukose2009}. 
For a given training input signal $u(n)  \in R^{N_u}$ a desired target output signal $y^{target}(n) \in R^{N_y}$
is known. Here $n = 1, . . . ,T$ is the discrete time and $T$ is the number of data points in the training dataset. The task is to learn a model with output $y(n) \in R^{N_y}$, where $y(n)$ matches $y^target(n)$ as well as possible, minimizing an error measure $E(y,y^target)$, and, more importantly, generalizes well to unseen data. The untrained RNN part of an ESN is called a dynamical reservoir, and the resulting states x(n) are termed echoes of its input history \citep{Lukose2012}. Finally, these signals are sent to an output layer as shown in the \figurename
$.$\ref{figura3}.
\begin{figure}[h] 
 \centering
 \includegraphics[scale=.9]{Reservorio}
 \caption{An echo state network \citep{Lukose2012}.} 
 \label{figura3} 
\end{figure}
 
The connections between the different elements of an Echo State Network have weights randomly generated. The weights of the internal connections of the reservoir $(W)$ as well as the weights of the input layer $(W_in)$, after being generated are set statically during all stages of implementation of the algorithm. The weights between the reservoir and the output layer $(W_out)$ are subject to changes of a supervised learning algorithm to correct the degree of error generated by the entire system \citep{Lukose2012}.

\subsubsection{Related works}
Huang et al. \citep{Huang2010}  surveyed the development of soft computing techniques in agricultural and biological engineering, including fuzzy logic, artificial neural networks, genetic algorithms, bayesian inference and decision trees.

A related work, proposed by Romero \citep{Romero1995} relies on regression models using a stepwise procedure to predict incubation and latency times of black Sigatoka. The author performed experiments on two farms located in Costa Rica (La Rita and Waldeck, the same as those used in this study but with different names). The study used data from: December 1993 to August 1995. Romero concluded that the model to predict the incubation period accounted a $R^2$ of 69\% in his observed data but it was not a good predictor when it was validated against an independent dataset (cross validation). For latency, he developed two models that accounted a $R^2$ of 78\% \hl{PONER EL VALOR OBTENIDO} in the observed data, however, when validated against an independent dataset (cross validation), the model was incorrect \hl{PONER EL VALOR OBTENIDO} for Weldeck, and for Rita obtained an adjusted $R^2$ of 82\%. 
\marginnote{Revisar si se puede implementar la propuesta de este autor para comparar}

Glezakos et al. \citep{Glezakos2010} proposed to use Genetic Algorithms (GA) and Neural Networks (NN) to identify plant virus (Tobacco Rattle Virus (TRV) and the Cucumber Green Mottle Mosaic Virus (CGMMV)). This is achieved by the development of ana- lytical tools of evolutionary adaptive width, propelled by Genetic Algorithms (GAs) and Neural Networks (NNs). The method was tested against some of the most commonly used classifiers in machine learning (Bayes, Trees and k-NN) via cross-validation and proved its potential towards the identification. 

In the agricultural context, Alves et al. \citep{Alves2011} used  geoinformation techniques to develop predictive models to study the areas of risk to soybean rust in soybean, coffee leaf rust in coffee, and black Sigatoka in banana, considering Brazil’s climatic characterization and the distribution of soybean, coffee and banana crops. Temperature and rainfall data were obtained for the period from 1950 to 2000, and of simulations for 2020, 2050 and 2080 using the SRES A2 climate change scenarios. Using principal components analysis, a single variable was generated based on 57 variables, in order to determine an index explaining 87\%, 88\% and 90\% of the variability of soybean, coffee and banana crops, respectively, in municipal districts across Brazil. The climatic model was used to generate the zoning of the three plant diseases, using temperature and leaf wetness as input. Areas of favorability for the diseases were plotted against the main coffee, soybean and banana growing areas in Brazil. This methodology enabled the visualization of the changes in areas favorable for epidemics under possible future scenarios of climate change.

Other applications of machine learning methods in precision agriculture include the use of support vector regression to predict carcass weight in beef cattle in advance to the slaughter  \citep{Alonso2013}, machine learning assessments of soil drying for agricultural planning \citep{Coopersmith2014}, and early detection and classification of plant diseases with support vector machines based on hyperspectral reflectance \citep{Rumpf2010}.

Furthermore, there have been attempts to generate software tools. Camargo et al. \citep{Camargo2012} presented an information system for the assessment of plant disorders (Isacrodi). They proposed that experts will attain a much better accuracy than the Isacrodi classifier, particularly when provided with samples from the affected crop. However, those cases where such expertise is not available, they suggest that Isacrodi can provide valuable support to farmers. Isacordi includes 15 crop disorders, but the black Sigatoka no is one of them. The prediction process is based on multi-class support vector machines.

Regarding the prediction of the develpment of the black Sigatoka with machine learning methods, Bendini et al. \citep{Bendini2013}  presented a study about the risk analysis of black Sigatoka occurrence based on polynomial models. A case study was developed in a commercial banana plantation located in Jacupiranga, Brazil. It was monitored weekly during the period from February to December 2005. Data included the weekly monitoring of the disease’s evolution stage, time series of meteorological data and remote sensing data. They obtained a model to estimate the evolution of the disease from satellite imagery. This model relates gray levels (NC) of the band 2 images of the Landsat-5 satellite, with the progress status or disease severity (EE). The authors claim to reach an $R^2$ of 90\%.

Also there are works related to banana fruit. Soares et al. \citep{Soares2014} apply two techniques: artificial neural networks (ANNs) and multiple linear regression (MLR) in banana plant to predict the yield, their results show that the neural network proved to be more accurate in forecasting the weight of the bunch in comparison to the multiple linear regressions in terms of the mean prediction-error $(MPE = 1.40)$, mean square deviation $(MSD = 2.29)$ and coefficient of determination $(R^2 = 91\%)$.

In general, the machine learning methods applied to predict the evolution of plant diseases, can be classified in two main approaches: 1) Those whose main inputs are images, and 2) Those whose main inputs are environmental and biological variables. Our study focuses in the second case.

\subsubsection{Data}
In this work we use data acquired in two research farms of Corbana in Costa Rica: 1) 28 Millas (previously called Waldeck and located at Matina) and La Rita (located at Pococí), both in the province of Limón, Costa Rica. The banana type is Musa AAA, subgroup Cavendish, cv. Grande Naine. The \tablename $.$\ref{tabla1} shows the variables available.

\begin{table}[h] 
\caption{Variables used in the study} 
\label{tabla1} 
\centering
\begin{tabular}{c|c} 
\hline
\bfseries Variable & \bfseries Meaning0'0' \\ 
\hline\hline 
$T_{a_max}$ &	Max air temperature \\
$T_{a_min}$ &	Min air temperature \\
$\overline{T}_{a}$	 & Mean air temperature \\
$H$	&  Humidity \\
$H_min$ &	Min humidity \\
$H_max$	& Max humidity \\
$R$	& Solar radiation \\
$\overline{P}$	& Mean precipitation  \\
$W_max$	& Max speed wind \\
$\overline{W}$	& Mean speed wind  \\
$L_2$	& Biological warning system – Leaf 2 \\
$L_3$	& Biological warning system – Leaf 3 \\
$L_4$	& Biological warning system – Leaf 4 \\
$E_s$	& Biological warning system – Evolution Stage \\
\hline
\end{tabular} 
\end{table}

The value to be predicted in all cases was $E_s$, that is the total measure of the biological warning system.  
\marginnote{Mas detalle aqui?  o ampliar en los conceptos?}

The data on the biological warning system are collected once a week. Although Corbana has meteorological stations that take data every five minutes, for these experiments, weekly averages generated by nearby stations to each of the farms were used.

The time intervals used for this study were: La Rita, week 48 of 2002 to week 17 of the 2015 (647 weeks) and for 28 Miles, week 37 of 2003 to week 18 of 2015 (605 weeks).

\subsubsection{Data preprocessing}

In 28 Miles farm, 1\% of the data were missing, while in La Rita was 2.25\%. To fill-in the missing values we use spline interpolation. The data collected did not exhibit outliers.

Due the fact that the variables measure meteorological or biological process, they are discretized in order to reflect trends in the data, i.e. the continuous values are not directly used. The coefficient of variation $C_v(x)$ of each variable x was used to determine the number $n$ of discretization levels.
$$n= \lfloor 100 \ C_v(x) \rfloor$$
where $\lfloor \ \rfloor$  is the round operator.

Each discretization range was uniformly partitioned. Besides enabling the capture of tendencies, the discretization removes the effect of small variations in the data collection, either by inaccuracies of the instruments (meteorological variables) or by subjective bias introduced by the human who collects the data (biological warning system). \hl{ESTO DEBE ESTAR DESCRITO EN ALGUNA PARTE}

Each feature was scaled to fit in a range between 0 and 1. The variable to be predicted was not scaled.

\subsection{Evaluation criteria}

Although there are many types of indicators to assess the quality of the prediction, we selected the root mean square error $(RMSE)$ and the determination coefficient $(R^2)$.  

Given $n$ records, let be $y$ the actual value of the series, $\hat{y}$ the predicted value and $\acute{y}$ the mean of the observed data.
$$RMSE = \sqrt{ \sum_{i=1}^{n} \frac{{(y-\hat{y})}^2}{n} }$$

$$ \bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i $$

$$ S_e^2 = \frac{\sum_{i=1}^{n} {(y_i-\hat{y}_i)}^2 }{n}$$

$$ S_R^2 = \frac{\sum_{i=1}^{n} {(\hat{y}_i-\bar{y}_i)}^2 }{n}$$

$$ S_y^2 = S_R^2 + S_e^2$$

$$ R^2 = \frac{S_R^2}{S_y^2}$$
	
This decision is supported by the widespread use in machine learning and agriculture areas \citep{Soares2014}, \citep{Soares2013}, \citep{Ibrahim2014} and \citep{Demir2014}.  

\subsection{Methodology}
The selection of methods and their parametrisation was performed in two stages.

{\bf Phase one } 

In the phase one, we did ten-fold-cross-validation on a set of  machine learning methods and different configurations:

\begin{itemize}
\item 	Patterns: n by m, where n from 1 to 8 and m from 1 to 3.

\item Methods: support vector regression with the kernels functions: linear, RBF (Gaussian) and sigmoid; echo state networks; ordinary least squares linear regression and ridge regression.

\item Variables included in the model:
\begin{itemize}
\item All variables.
\item from the set $\{ \overline{T}_{a} , H, \overline{P} , \overline{W}  \}$ use the subsets with one, two or four elements. These variables are according to experts the ones having most impact on the disease development \citep{MarinVargas1995}.
\end{itemize}

\end{itemize}

{\bf Phase two }

In the second phase, the best configurations obtained in phase one are used to validate with the last 52 and 102 weeks. 

This second phase intents to expose how these methods behave on a considerable climate in the years 2014 and 2015.
\marginnote{Poner una cita que fundamente este ultimo parrafo}

\subsection{Programming environment}

We use the python programming language with the Integrated Development Environment (IDE) Spyder \citep{Continuum2015}, particularly with the libraries pandas \citep{mckinneypandas2010} and numpy \citep{vanderWalt2011}. For SVR, ridge and ordinary least squares regressions, we used sklearn \citep{scikitlearn2011} and for ESN the python-based code of Dr. $Luko\breve{s} evi \breve{c} ius$ \citep{Lukose2012} on which the necessary were done for adjustments for the experiments of this work. The computer used a processor Intel(R) Core™ i7-4800MQ CPU @ 2.70GHz, 16.0 GB RAM, running Windows 8 Pro.

\section{Results}

\section{Discussion and conclusions}

\section{References}

\begin{thebibliography}{1}


\bibitem[Camargo et al.,2012]{Camargo2012} Camargo, A., Molina, J., Cadena-Torres, J., Jim\'enez, N., Kim, J. 2012. Intelligent systems for the assessment of crop disorders. Computers and Electronics in Agriculture(85), 1-7. doi:10.1016/j.compag.2012.02.017.

\bibitem[Chuang and Jeger, 1987]{ChuangJeger1987} Chuang, T., Jeger, M. 1987. Predicting the Rate of Development of Black Sigatoka ( Mycosphaerella fijiensis var. difformis ) Disease in Southern Taiwan. Phytopathology, 77, 1542-1547.

\bibitem[Huang et al., 2010]{Huang2010} Huang, Y., Lan, Y., Thomson, S., Fang, A., Hoffmann, W., Lacey, R. 2010. Development of soft computing and applications in agricultural and biological engineering. Computers and Electronics in Agriculture,(71(2)), 107–127. doi:10.1016/j.compag.

\bibitem[Kim et al., 2014]{Kim2014} Kim, Y., Yoo, S., Gu, Y., Lim, J., Han, D.,  Baik, S. 2014. Crop Pests Prediction Method Using Regression and Machine Learning Technology: Survey. IERI Procedia(6), 52–56. doi:10.1016/j.ieri.2014.03.009.

\bibitem[Marin and Romero, 1995]{MarinVargas1995} Marin Vargas, D., Romero Calderón, R. 1995. El combate de la Sigatoka Negra. Bolet\'in Departamento de Investigaciones, Corbana Costa Rica.


\bibitem[Marin et al., 2003]{Marinetal2003} Marin, D., Romero, R., Guzman, M, Sutton, T. 2003. Black Sigatoka: An increasing threat to banana cultivation. Plant Disease, 87(3), 208-222.


\bibitem[Zhao et al., 2013]{Zhao2013}Zhao, L., He, L., Harry, W., Jin, X. 2013. Intelligent Agricultural Forecasting System Based on Wireless Sensor. Journal of Networks(8), 1817–1824. doi:10.4304/jnw.8.8.1817-1824.

\bibitem[Wei et al., 2013]{Wei2013} Wei, Z., Tao, T., ZhuoShu, D.,  Zio, E. (2013). A dynamic particle filter-support vector regression method for reliability prediction. Reliability Engineering \& System Safety, 109–116. doi:10.1016/j.ress.2013.05.021.

\bibitem[Libro SVM XXXX, 201X]{XXXX201X} Libro SVM XXXX.

\bibitem[Alonso et al., 2013]{Alonso2013} Alonso, J., Rodríguez Castañón, Á., Bahamonde, A. (2013). Support Vector Regression to predict carcass weight in beef cattle in advance of the slaughter. Computers and Electronics in Agriculture, 116-120.

\bibitem[Pedregosa et al., 2013] {scikitlearn2011} Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E. (2011) Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, vol. 12, 2825--2830.

\bibitem[Lukosevicius and Jaeger, 2009] {Lukose2009} Lukosevicius, M. and Jaeger, H. (2009). Reservoir computing approaches to recurrent neural network training. Computer Science Review(3), 127–149. doi:10.1016/j.cosrev.2009.03.005.

\bibitem[Lukosevicius, 2012] {Lukose2012} Lukosevicius, M. (2012). A Practical Guide to Applying Echo State Networks. Neural Networks: Tricks of the Trade. 1-20

\bibitem[Romero, 1995] {Romero1995}  Romero, R. (1995). Dynamics of fungicide resistant populations of Mycosphaerella fijiensis and Epidemiology of black Sigatoka of banana. Costa Rica: North Carolina State University.

\bibitem[Glezakos et al., 2010] {Glezakos2010} Glezakos, T., Moschopoulou, G., Tsiligiridis, T., Kintzios, S., Yialouris, C. (2010). Plant virus identification based on neural networks with evolutionary preprocessing. Computers and Electronics in Agriculture, 70, 263–275.

\bibitem[Alves et al., 2011] {Alves2011} Alves, M., de Carvalho, L., Pozza, E., Sanches, L., Maia, J. (2011). Ecological zoning of soybean rust, coffee rust and banana black sigatoka based on Brazilian climate changes. Procedia Environmental Sciences, 6, 35-49.

\bibitem[Coopersmith et al., 2010] {Coopersmith2014} Coopersmith, E. J., Minsker, B. S., Wenzel, C. E., Gilmore, B. J. (2014). Machine learning assessments of soil drying for agricultural planning. Computers and Electronics in Agriculture, 104, 93–104. http://doi.org/10.1016/j.compag.2014.04.004

\bibitem[Rumpf et al., 2010] {Rumpf2010} Rumpf, T., Mahlein, a.-K., Steiner, U., Oerke, E.-C., Dehne, H.-W., Plümer, L. (2010). Early detection and classification of plant diseases with Support Vector Machines based on hyperspectral reflectance. Computers and Electronics in Agriculture, 74(1), 91–99. http://doi.org/10.1016/j.compag.2010.06.009

\bibitem[Bendini et al., 2010] {Bendini2013} Bendini, H., Moraes, W., da Silva, S., Tezuka, E., Cruvinel, P. (2013). Análise de risco da ocorrência de Sigatoka-negra baseada em modelos polinomiais: um estudo de caso. Tropical Plant Pathology, 38, 035-043.

\bibitem[Soares et al., 2014] {Soares2014} Soares, J., Pasqual, M., Lacerda, W., Silva, S., Donato, S. (2014). Comparison of techniques used in the prediction of yield in banana plants. Scientia Horticulturae journal, 167, 84-90.

\bibitem[Soares et al., 2013] {Soares2013} Soares , J., Pasqual, M., Lacerda, W. (2013). Utilization of artificial neural networks in the prediction of the bunches’weight in banana plants. Scientia Horticulturae(155), 24-29.

\bibitem[Ibrahim and Wibowo, 2014] {Ibrahim2014}  Ibrahim, N. and Wibowo, A. (2014). Time Series Support Vector Regression with Missing Data Treatment Based Variables Selection for Water Level Prediction of Galas River in Kelantan Malaysia. International Journal of Applied Research in Engineering and Science, 3, 25-36.

\bibitem[Demir and Bruzzone, 2014] {Demir2014} Demir, B. and Bruzzone, L. (2014). A multiple criteria active learning method for support vector regression. Pattern Recognition, 2558–2567. doi:10.1016/j.patcog.2014.02.001

\bibitem[Continuum Analitycs, 2015] {Continuum2015} Continuum Analitycs. (2015). Anaconda. Retrieved from https://www.continuum.io/

\bibitem[McKinney, 2010] {mckinneypandas2010} McKinney W. (2010). Data Structures for Statistical Computing in Python, Proceedings of the 9th Python in Science Conference, 51-56 

\bibitem[van der Walt et al., 201] {vanderWalt2011} van der Walt S., Colbert C. and Varoquaux G. (2011). The NumPy Array: A Structure for Efficient Numerical Computation, Computing in Science \& Engineering, 13, 22-30 (2011), DOI:10.1109/MCSE.2011.37 




\end{thebibliography}

\end{document}