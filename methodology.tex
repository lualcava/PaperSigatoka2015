\section{Specification of data and methodology}
\label{sec:data}

Since the suitability of a machine learning technique to a particular
problem is entirely depend on the nature of the data, we describe in
this section, first, the data set employed in the study, followed by
the methodology to compare the chosen techniques under consideration
of their parameter space.

\subsection{Data}

The data used for the current study was acquired in two research farms
of Corbana in Costa Rica%
%
\footnote{Both farms were also use in the study of \citet{Romero1995}.  Back
  then, \emph{La Rita} was referred to as \emph{Waldeck}.}
%
: \emph{28 Millas} located in the region of Matina, and \emph{La Rita}
located in Pococí, both in the province of Limón, Costa Rica.
%
Both farms produce banana fruit \emph{Musa} sp.\ AAA group `Grande
Naine' (Cavendish subgroup). 

The available input and output variables are summarized in
\tabref{tab:variables}.
%
\begin{table}[h] 
\centering
\begin{tabular}{l|l|c} 
\hline
\textbf{Symbol}  & \textbf{Description} & \textbf{Units} \\ 
\hline\hline 
$T_{a_{max}}$       & Maximal air temperature & $[^\circ$C$]$ \\
$T_{a_{min}}$       & Minimal air temperature & $[^\circ$C$]$ \\
$\overline{T}_{a}$ & Mean air temperature    & $[^\circ$C$]$ \\
$\overline{H}$    & Mean relative humidity           & $[0 - 100]$   \\
$H_{min}$          & Minimal relative humidity        & $[0 - 100]$  \\
$H_{max}$          & Maximal relative humidity        & $[0 - 100]$  \\
$\overline{R}$    & Mean solar radiation    & $[W/m^2]$ \\
$P$               & Precipitation       & $[mm]$ \\
$W_{max}$          & Maximal wind speed      & $[m/s]$ \\
$\overline{W}$    & Mean speed wind         & $[m/s]$ \\
\hline
$E_s$             & Biological warning system – Evolution Stage  & $>0$\\
\hline
\end{tabular} 
\caption{Variables available for the learning algorithms} 
\label{tab:variables} 
\end{table}

The data was captured for La Rita between the 48\,th week of
2002 to the 17\,th week of 2015 (647 weeks); for 28 Miles the
data was captured between the 37\,th week of 2003 and the
18\,th week of 2015 (605 weeks).
%
The data on the biological warning system were collected once a
week.

The meteorological stations of Corbana acquire data every five
minutes.
%
\todofn{However, for the current study weekly averages were used,}
{Hay que explicar por qué? $\rightarrow$ reducción de ruido, etc.}
%
computed on the data collected by nearby stations in each farm.


\TODO{Alex, Falta explicar cada variable y sus
  unidades y rangos usuales, lo que es relevante luego cuando se hable
  de la normalización.
  
  Humidity ¿cuál se usa? ¿la relativa? ¿la absoluta?, ¿la
  específica?  Las otras unidades las supuse, así que hay que revisar
  que estén bien!

  No tengo idea qué es el ``Sum precipitation'' y en qué unidades
  estaría.  Parece no ser algo estándar o medido directamente, ¿o sí?
  así que amerita una explicación aquí.

  Dijiste que las variables se promedian para una semana.  ¿Qué
  significan entonces las variables que dicen ``mean''?
}

\TODO{The mean variables ... }

The value to be predicted in all cases is the evolution stage $E_s$,
which is a measure of the level of disease progression.

\subsection{Data preprocessing}

Data taken on real farms during more than a decade is expected to
contain outliers, noise and missing samples.  These problems are
caused by human errors or by technical defects on the instruments
used.  
%
In the preprocessing step described in this section these problems
need to be detected and fixed before moving them to the next
processing stages.

In the farm 28 Miles 1\% and in La Rita 2.25\% of the data were missing.
%
To fill-in the missing values \todofn{spline interpolation}{falta una
  referencia} was used.
%
The data collected did not exhibit outliers.

Due the fact that the variables measure meteorological or biological
processes, they are discretized \todofn{in order to reflect data trends}%
%
{Formalmente la discretización NO captura tendencias, sino la derivada
  de la función en el tiempo.  Para que no se capture ruido uno
  simplemente usa un filtro pasabajas primero (los estadísticos le
  dicen diferente, pero no sé cómo).  En otras palabras, si querés la
  tendencia, con usar la derivada de un filtro gaussiano sobre los
  datos ya se ve la tendencia muy bien con el signo de esa derivada.
  Con la varianza del filtro uno ajusta qué nivel de detalle le
  interesa, o lo qué es lo mismo, cuanto tiempo quiere usar para el
  pronóstico de tendencias (variable crece, está igual o decrece).  El
  valor de salida de la derivada filtrada también se puede discretizar
  si solo interesa esa tendencia de forma difusa, pero quizá para la
  regresión es mejor mantenerla continua (si está filtrada, con un
  filtro o mejor aún con un banco de filtros, al estilo wavelets).

  Eso es TOTALMENTE independiente de la cuantificación.  Ahora, un
  cuantificador tiene en principio un efecto de filtro pasabajas, pero
  eso reduce el ruido y en realidad no dice nada de tendencias.  En
  resumen, formalmente la cuantificación en sí no refleja nada de un
  comportamiento temporal, y ``tendencia'' es en principio un
  comportamiento temporal!}.
%
The variation range of each variable is uniformly discretized.
%
This discretization removes the effect of small variations in the data,
either by inaccuracies of the instruments (meteorological variables)
or by subjective bias introduced by the human collecting the data
(biological warning system).

The coefficient of variation
$C_v(x)={\sqrt{E((x-E(x))^2)}}/{E(x)}$ of each variable $x$ is
used to determine the number $n$ of discretization levels as
\todofn{$n=\lfloor 100 \ C_v(x) \rfloor$,}%
%
{Hay algo que no entiendo.  ¿De dónde sale el 100?  ¿Por qué 100?
  Así como está esto, el mismo rango de variación de temperatura
  produce diferentes $n$, con solo un cambio en el promedio!  Eso es
  muy extraño.  Por otro lado, los rangos de las variables son tan
  diferentes, que el número $n$ va a terminar siendo casi cualquier
  cosa.  Yo hubiese esperado que la desviación estándar se use para
  discretizar las variables.  Otro problema formal más serio, es que
  el coeficiente de variación solo se puede usar/tiene sentido si la
  escala de medición es de razón, y la temperatura, la precipitación y
  la humedad son usualmente mediciones de intervalo! Los $L_i$ ni tan
  siquiera sé qué son porque creo que son algo subjetivos a la persona
  que los toma ¿no?, aunque creo que iban con el porcentaje de área
  afectado, lo que también sería medición de intervalo!}
%
where $\lfloor \cdot \rfloor$ is the round operator.


Each feature \todofn{was scaled}{¿escaladas cómo? ¿$sx$? ¿$sx+b$?
  ¿$sf(x)$?} to fit in the range 0 and 1. The variable $E_s$ to be
predicted was not scaled.

\TODO{Aquí faltan la fórmula general de normalización usada.  Lo que
  sigue lo estoy asumiendo, pero puede ser que no sea así}

Each variable $x\in[x_{\min},x_{\max}]$ was normalized into the
interval $[0,1]$ with the linear map $x_n = mx+b$ with
$m=1/(x_{\max}-x_{\min})$ and $b=-mx_{\min}$.

\TODO{Explicar brevemente la razón de la normalización, ojalá con una
  referencia bibliográfica}


\subsection{Evaluation criteria}

Although there are many types of indicators to assess the quality of
the prediction, here the coefficient of determination $(R^2)$ and the
Root Mean Square Error $(RMSE)$.
%
This decision is supported by the widespread use of the former
indicator in the agriculture and the latter in machine learning
\citep{Soares2013,Soares2014,Ibrahim2014,Demir2014}.

Given $n$ records $y_i$, $i=1\ldots{}n$ of the actual outcome of a
process. The mean $\bar{y}$ of the observed data is given by
\begin{equation*}
  \bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i
\end{equation*}
Let $\hat{y}_i$ be the predicted value for $y_i$. Then, the mean
square error (MSE) $S_e^2$ and the \review{¿cómo se llama esto?
  ¿unexplained variance?} $S_R^2$ are estimated as
\begin{align*}
S_e^2 &= \frac{\sum_{i=1}^{n} {(y_i-\hat{y}_i)}^2 }{n} &
S_R^2 &= \frac{\sum_{i=1}^{n} {(\hat{y}_i-\bar{y})}^2 }{n}
\end{align*}
The root mean square error is defined as $RMSE = \sqrt{S_e^2}$ and the
coefficient of determination is
\begin{equation*}
R^2 = \frac{S_R^2}{S_R^2 + S_e^2}
\end{equation*}
 

\TODO{Favor revisar.  Vi una representación en términos de $R^2=1 -
  MSE/\sigma^2$ (con $\sigma^2$ la varianza), que no sé si está bien o
  no, pero lo mejor será poner la fuente de donde se tomó la anterior
  definición.  Había en el $S_R^2$ un $\bar{y}_i$ pero el promedio no
  depende de $i$ por lo que no tenía sentido.  Supuse que era el
  promedio, pero no sé.  El cuadrado en las $S^2$ ¿está bien?, o
  indirectamente estás diciendo que $RMSE=S_e$, que sería una mejor
  notación matemática (dejando RMSE solo como abreviatura textual)!}

\subsection{Programming environment}

We use the Python programming language \todofn{with the Integrated
  Development Environment (IDE)}%
{El IDE es para la reproducción de resultados irrelevante, y por lo
  tanto información circunstancial que es mejor evitar.  Lo relevante
  es lo que tenga efectos directos en los resultados.  Si yo prefiero
  usar un editor de texto corriente para programar, el restulado final
  es el mismo, si uso el mismo compilador/intérprete.  Eso es la
  información relevante: ¿qué versión de Python concretamente? ¿Se
  compiló el Python o se usó interpretado?  ¿Cuáles versiones de
  Pandas y Numpy en concreto se usaron?} %
Spyder \citep{Continuum2015}, particularly with the libraries Pandas
\citep{mckinneypandas2010} and Numpy \citep{vanderWalt2011}.

The implementation for SVR, ridge and ordinary least squares
regressions in scikit-learn \citep{scikitlearn2011} were used.
%
Adjustments to the ESN implementation code of \citet{Lukose2012} were
necessary to allow its integration into our experimental
framework.

All experiments were performed on a PC computer with an
Intel\textsuperscript{\textregistered} Core i7-4800MQ processor,
2.70\,GHz, 16.0\,GB RAM, under the operating system MS Windows 8 Pro.

\subsection{Methodology}

The evaluation of the techniques under consideration of their
parameter space, was performed in two stages, described below.

\subsubsection{Phase one} 

In the phase one, ten-fold-cross-validation on the total set of
machine learning methods under a subset of configurations was evaluated:

\begin{itemize}
\item Patterns: $n\times{}m$, with $n=1\ldots{}8$ and $m=1\ldots{}2$.
\TODO{No se entiende que quiere decir eso!!}
\item Methods: support vector regression with the kernels linear,
  gaussian and sigmoid; echo state networks; ordinary least squares
  linear regression, ridge regression and elastic-net regression.
  \TODO{Cada uno de esos métodos tiene a su vez un espacio
    paramétrico.  Eso tiene que quedar claro aquí: cómo se barrió el
    espacio paramétrico, para saber el nivel de detalle de la prueba!
    Eso es importantísimo, porque si no no se puede decir nada
    respecto a los métodos, sino solo respecto la configuración
    concreta probada!}
\item Variables included in the model:
\begin{itemize}
\item All variables.
\item From the set $\{ \overline{T}_{a} , \overline{H}, P ,
  \overline{W} \}$ use the subsets with one, two or four
  elements. These variables have the largest impact on the disease
  development \citep{MarinVargas1995}.
\end{itemize}

\end{itemize}

\subsubsection{Phase two} 

In the second phase, the best configurations obtained in phase one are
used to validate with the last 50 and 100 weeks.

\TODO{Hmm, ¿entonces cuántas/cuáles semanas se usaron para la fase uno?}
