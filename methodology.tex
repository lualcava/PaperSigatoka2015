\section{Specification of data and methodology}
\label{sec:data}

In this section, we present the data and how we worked to obtain our results.

\subsection{Data}
We use data acquired in two research farms of Corbana in Costa Rica: 1) 28 Millas (previously called Waldeck and located at Matina) and La Rita (located at Pococí), both in the province of Limón, Costa Rica. The banana type is Musa AAA, subgroup Cavendish, cv. Grande Naine. The \tablename $.$\ref{tabla1} shows the variables available.

\begin{table}[h] 
\caption{Variables used in the study} 
\label{tabla1} 
\centering
\begin{tabular}{c|c} 
\hline
\bfseries Variable & \bfseries Meaning0'0' \\ 
\hline\hline 
$T_{a_{max}}$ &	Max air temperature \\
$T_{a_{min}}$ &	Min air temperature \\
$\overline{T}_{a}$	 & Mean air temperature \\
$\overline{H}$	&  Mean Humidity \\
$H_{min}$ &	Min humidity \\
$H_{max}$	& Max humidity \\
$\overline{R}$	& Mean Solar radiation \\
$P$	& Sum precipitation  \\
$W_{max}$	& Max speed wind \\
$\overline{W}$	& Mean speed wind  \\
$L_2$	& Biological warning system – Leaf 2 \\
$L_3$	& Biological warning system – Leaf 3 \\
$L_4$	& Biological warning system – Leaf 4 \\
$E_s$	& Biological warning system – Evolution Stage \\
\hline
\end{tabular} 
\end{table}

The value to be predicted in all cases was $E_s$, that is the total measure of the biological warning system.  

The data on the biological warning system are collected once a week. Although Corbana has meteorological stations that take data every five minutes, for these experiments, weekly averages generated by nearby stations to each of the farms were used.

The time intervals used for this study were: La Rita, week 48 of 2002 to week 17 of the 2015 (647 weeks) and for 28 Miles, week 37 of 2003 to week 18 of 2015 (605 weeks).

\subsection{Data preprocessing}
Usually, data need preprocessing to prepare for use. In this section we explain that process.

In 28 Miles farm, 1\% of the data were missing, while in La Rita was 2.25\%. To fill-in the missing values we use spline interpolation. The data collected did not exhibit outliers.

Due the fact that the variables measure meteorological or biological process, they are discretized in order to reflect trends in the data, i.e. the continuous values are not directly used. The coefficient of variation $C_v(x)$ of each variable x was used to determine the number $n$ of discretization levels.
$$n= \lfloor 100 \ C_v(x) \rfloor$$
where $\lfloor \ \rfloor$  is the round operator.

Each discretization range was uniformly partitioned. Besides enabling the capture of tendencies, the discretization removes the effect of small variations in the data collection, either by inaccuracies of the instruments (meteorological variables) or by subjective bias introduced by the human who collects the data (biological warning system). 

Each feature was scaled to fit in a range between 0 and 1. The variable to be predicted was not scaled.

\subsection{Evaluation criteria}

Although there are many types of indicators to assess the quality of the prediction, we selected the determination coefficient $(R^2)$ and the Root Mean Square Error $(RMSE)$.  

Given $n$ records, let be $y$ the actual value of the series, $\hat{y}$ the predicted value and $\acute{y}$ the mean of the observed data.

$$ \bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i $$

$$ S_e^2 = \frac{\sum_{i=1}^{n} {(y_i-\hat{y}_i)}^2 }{n}$$

$$ S_R^2 = \frac{\sum_{i=1}^{n} {(\hat{y}_i-\bar{y}_i)}^2 }{n}$$

$$ S_y^2 = S_R^2 + S_e^2$$

$$ R^2 = \frac{S_R^2}{S_y^2}$$

$$ RMSE = \sqrt{\frac{\sum_{i=1}^{n} {(y_i-\hat{y}_i)}^2 }{n}}$$
	
This decision is supported by the widespread use in machine learning and agriculture areas \citep{Soares2014}, \citep{Soares2013}, \citep{Ibrahim2014} and \citep{Demir2014}.  

\subsection{Programming environment}

We use the python programming language with the Integrated Development Environment (IDE) Spyder \citep{Continuum2015}, particularly with the libraries pandas \citep{mckinneypandas2010} and numpy \citep{vanderWalt2011}. For SVR, ridge and ordinary least squares regressions, we used sklearn \citep{scikitlearn2011} and for ESN the python-based code of Dr. $Luko\breve{s} evi \breve{c} ius$ \citep{Lukose2012} on which the necessary were done for adjustments for the experiments of this work. The computer used a processor Intel(R) Core i7-4800MQ CPU 2.70GHz, 16.0 GB RAM, running Windows 8 Pro.

\subsection{Methodology}
The selection of the technique and its parametrisation was performed in two stages that they are presented below.

{\bf Phase one } 

In the phase one, we did ten-fold-cross-validation on a set of  machine learning methods and different configurations:

\begin{itemize}
\item 	Patterns: n by m, where n from 1 to 8 and m from 1 to 2.

\item Methods: support vector regression with the kernels functions: linear, gaussian and sigmoid; echo state networks; ordinary least squares linear regression, ridge regression and elastic-net regression.

\item Variables included in the model:
\begin{itemize}
\item All variables.
\item From the set $\{ \overline{T}_{a} , \overline{H}, P , \overline{W}  \}$ use the subsets with one, two or four elements. These variables are according to experts the ones having most impact on the disease development \citep{MarinVargas1995}.
\end{itemize}

\end{itemize}

{\bf Phase two }	

In the second phase, the best configurations obtained in phase one are used to validate with the last 50 and 100 weeks. 
